{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modeling_video_game_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Global_players</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>Sequel</th>\n",
       "      <th>Lifecycle</th>\n",
       "      <th>MaxPlayers</th>\n",
       "      <th>Online</th>\n",
       "      <th>Licensed</th>\n",
       "      <th>Handheld</th>\n",
       "      <th>...</th>\n",
       "      <th>Genre_Misc</th>\n",
       "      <th>Genre_Platform</th>\n",
       "      <th>Genre_Puzzle</th>\n",
       "      <th>Genre_Racing</th>\n",
       "      <th>Genre_Role-Playing</th>\n",
       "      <th>Genre_Shooter</th>\n",
       "      <th>Genre_Simulation</th>\n",
       "      <th>Genre_Sports</th>\n",
       "      <th>Genre_Strategy</th>\n",
       "      <th>NA_Sales_More_Eu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.84</td>\n",
       "      <td>71.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>1.27</td>\n",
       "      <td>75.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>0.68</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>0.46</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Release  Global_players  Critic_Score  User_Score  Sequel  \\\n",
       "0             2012            0.84          71.0         7.9     0.0   \n",
       "1             2002            1.27          75.0         8.5     0.0   \n",
       "2             2002            0.68          76.0         8.9     0.0   \n",
       "3             2002            0.46          70.0         8.7     0.0   \n",
       "4             2000            0.53          51.0         4.6     0.0   \n",
       "\n",
       "   Lifecycle  MaxPlayers  Online  Licensed  Handheld  ...  Genre_Misc  \\\n",
       "0        0.0         1.0     0.0       0.0       0.0  ...           0   \n",
       "1        0.0         1.0     0.0       0.0       0.0  ...           0   \n",
       "2        0.0         1.0     0.0       0.0       0.0  ...           0   \n",
       "3        0.0         1.0     0.0       0.0       0.0  ...           0   \n",
       "4        0.0         1.0     0.0       0.0       0.0  ...           0   \n",
       "\n",
       "   Genre_Platform  Genre_Puzzle  Genre_Racing  Genre_Role-Playing  \\\n",
       "0               0             0             0                   1   \n",
       "1               0             0             0                   1   \n",
       "2               0             0             0                   1   \n",
       "3               0             0             0                   1   \n",
       "4               0             0             1                   0   \n",
       "\n",
       "   Genre_Shooter  Genre_Simulation  Genre_Sports  Genre_Strategy  \\\n",
       "0              0                 0             0               0   \n",
       "1              0                 0             0               0   \n",
       "2              0                 0             0               0   \n",
       "3              0                 0             0               0   \n",
       "4              0                 0             0               0   \n",
       "\n",
       "   NA_Sales_More_Eu  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate target and other features\n",
    "target = df['NA_Sales_More_Eu']\n",
    "features = df.drop(['NA_Sales_More_Eu'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "sc=StandardScaler()\n",
    "#firt model to training data - not testing data\n",
    "X_train_scaled= sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create false data - similar to KNN\n",
    "sm = SMOTE(ratio=1.0)\n",
    "X_train_scaled, y_train = sm.fit_sample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([5915, 5915]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out some metrics about resulting prediction\n",
    "def print_metrics(labels, preds):\n",
    "    print(\"Precision Score: {}\".format(precision_score(labels, preds)))\n",
    "    print(\"Recall Score: {}\".format(recall_score(labels, preds)))\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(labels, preds)))\n",
    "    print(\"F1 Score: {}\".format(f1_score(labels, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline Logistic\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 0.7609903189969847\n",
      "Recall Score: 0.8129874533740251\n",
      "Accuracy Score: 0.7788233299423534\n",
      "F1 Score: 0.7861300106566113\n",
      "\n",
      "test\n",
      "Precision Score: 0.9136904761904762\n",
      "Recall Score: 0.8247145735392881\n",
      "Accuracy Score: 0.7989333333333334\n",
      "F1 Score: 0.8669255206494881\n",
      "-------------------\n",
      "True Positives: 1228\n",
      "True Negatives: 270\n",
      "False Positives: 116\n",
      "False Negatives: 261\n"
     ]
    }
   ],
   "source": [
    "#baseline logistic - use scaled data\n",
    "print('baseline Logistic')\n",
    "print('-------------------')\n",
    "lm = LogisticRegression()\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "print('train')\n",
    "train_preds = lm.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = lm.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline K Nearest Neighbors\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 0.9468976018271793\n",
      "Recall Score: 0.8435062733129874\n",
      "Accuracy Score: 0.8981010512037979\n",
      "F1 Score: 0.8922166427546628\n",
      "\n",
      "test\n",
      "Precision Score: 0.9005481597494127\n",
      "Recall Score: 0.7723304231027536\n",
      "Accuracy Score: 0.7514666666666666\n",
      "F1 Score: 0.831525668835864\n",
      "-------------------\n",
      "True Positives: 1150\n",
      "True Negatives: 259\n",
      "False Positives: 127\n",
      "False Negatives: 339\n"
     ]
    }
   ],
   "source": [
    "#baseline K Nearest Neighbors - use scaled data\n",
    "print('baseline K Nearest Neighbors')\n",
    "print('-------------------')\n",
    "lm = KNeighborsClassifier()\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "print('train')\n",
    "train_preds = lm.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = lm.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline Decision Tree\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 1.0\n",
      "Recall Score: 1.0\n",
      "Accuracy Score: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "test\n",
      "Precision Score: 0.8971308607417775\n",
      "Recall Score: 0.8609805238415044\n",
      "Accuracy Score: 0.8112\n",
      "F1 Score: 0.8786840301576423\n",
      "-------------------\n",
      "True Positives: 1282\n",
      "True Negatives: 239\n",
      "False Positives: 147\n",
      "False Negatives: 207\n"
     ]
    }
   ],
   "source": [
    "#baseline Decision Trees - use scaled data\n",
    "print('baseline Decision Tree')\n",
    "print('-------------------')\n",
    "lm = DecisionTreeClassifier()\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "print('train')\n",
    "train_preds = lm.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = lm.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline Random Forest\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 0.9982955513891256\n",
      "Recall Score: 0.993048491013903\n",
      "Accuracy Score: 0.995676500508647\n",
      "F1 Score: 0.9956651083722907\n",
      "\n",
      "test\n",
      "Precision Score: 0.9083969465648855\n",
      "Recall Score: 0.8791134989926125\n",
      "Accuracy Score: 0.8336\n",
      "F1 Score: 0.8935153583617748\n",
      "-------------------\n",
      "True Positives: 1309\n",
      "True Negatives: 254\n",
      "False Positives: 132\n",
      "False Negatives: 180\n"
     ]
    }
   ],
   "source": [
    "#baseline Random Forest - use scaled data\n",
    "print('baseline Random Forest')\n",
    "print('-------------------')\n",
    "lm = RandomForestClassifier()\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "print('train')\n",
    "train_preds = lm.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = lm.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline XGBoost\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 0.8390157606947571\n",
      "Recall Score: 0.8845371312309257\n",
      "Accuracy Score: 0.8574092912851814\n",
      "F1 Score: 0.8611753053813139\n",
      "\n",
      "test\n",
      "Precision Score: 0.9112508735150244\n",
      "Recall Score: 0.8757555406312961\n",
      "Accuracy Score: 0.8336\n",
      "F1 Score: 0.8931506849315067\n",
      "-------------------\n",
      "True Positives: 1304\n",
      "True Negatives: 259\n",
      "False Positives: 127\n",
      "False Negatives: 185\n"
     ]
    }
   ],
   "source": [
    "#baseline XGBoost - use scaled data\n",
    "print('baseline XGBoost')\n",
    "print('-------------------')\n",
    "lm = XGBClassifier()\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "print('train')\n",
    "train_preds = lm.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = lm.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Tuning\n",
    "- Logistic Regression had the biggest improvement to testing data\n",
    "- KNN doesn't perform as well as the other models, had a lot of False Negatives\n",
    "- Decision Trees looks well rounded\n",
    "- Random Forest looks overfit\n",
    "- XGBost looks to be the best model out of the bunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784630603985053\n",
      "{'C': 1, 'fit_intercept': True, 'max_iter': 70, 'penalty': 'l1'}\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=70, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Logistic Regression\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 0.76114902396445\n",
      "Recall Score: 0.813157002373686\n",
      "Accuracy Score: 0.7789928789420142\n",
      "F1 Score: 0.7862939585211902\n",
      "\n",
      "test\n",
      "Precision Score: 0.913626209977662\n",
      "Recall Score: 0.8240429818670248\n",
      "Accuracy Score: 0.7984\n",
      "F1 Score: 0.8665254237288137\n",
      "-------------------\n",
      "True Positives: 1227\n",
      "True Negatives: 270\n",
      "False Positives: 116\n",
      "False Negatives: 262\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Tuning\n",
    "grid_params_lr = [{'penalty': ['l1', 'l2'], \n",
    "                    'C' : [0.001,0.01,0.01,1,2,5,10],\n",
    "                    'fit_intercept': [True,False],\n",
    "                    'max_iter': range(70,130,10)}] \n",
    "\n",
    "gs_lr = GridSearchCV(estimator=LogisticRegression(),\n",
    "                    param_grid=grid_params_lr,\n",
    "                    scoring='f1',\n",
    "                    cv=5)\n",
    "gs_lr.fit(X_train_scaled, y_train)\n",
    "# examine the best model\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(gs_lr.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(gs_lr.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(gs_lr.best_estimator_)\n",
    "\n",
    "#print results\n",
    "print('Logistic Regression')\n",
    "print('-------------------')\n",
    "\n",
    "print('train')\n",
    "train_preds = gs_lr.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = gs_lr.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8804718475253878\n",
      "{'n_neighbors': 1, 'p': 1}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=1, p=1,\n",
      "           weights='uniform')\n",
      "K Nearest Neighbors\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 1.0\n",
      "Recall Score: 1.0\n",
      "Accuracy Score: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "test\n",
      "Precision Score: 0.8773388773388774\n",
      "Recall Score: 0.8600543478260869\n",
      "Accuracy Score: 0.7957333333333333\n",
      "F1 Score: 0.8686106346483704\n",
      "-------------------\n",
      "True Positives: 1266\n",
      "True Negatives: 226\n",
      "False Positives: 177\n",
      "False Negatives: 206\n"
     ]
    }
   ],
   "source": [
    "#KNN tuning\n",
    "grid_params_KNN = [{'n_neighbors': range(1,50,2),\n",
    "                    'p': [1,2,3]}] \n",
    "\n",
    "gs_KNN = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                           param_grid=grid_params_KNN,\n",
    "                           scoring='f1',\n",
    "                           cv=5,\n",
    "                           verbose=5)\n",
    "gs_KNN.fit(X_train_scaled, y_train)\n",
    "# examine the best model\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(gs_KNN.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(gs_KNN.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(gs_KNN.best_estimator_)\n",
    "\n",
    "#print results\n",
    "print('K Nearest Neighbors')\n",
    "print('-------------------')\n",
    "\n",
    "print('train')\n",
    "train_preds = gs_KNN.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = gs_KNN.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 252 candidates, totalling 1260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8549074453670996\n",
      "{'criterion': 'entropy', 'max_depth': 17, 'min_samples_leaf': 5}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=17,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=5, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Decision Trees\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 0.9263989245504957\n",
      "Recall Score: 0.9347236351305527\n",
      "Accuracy Score: 0.9302305866395388\n",
      "F1 Score: 0.9305426618280024\n",
      "\n",
      "test\n",
      "Precision Score: 0.8967428967428968\n",
      "Recall Score: 0.8690396239086635\n",
      "Accuracy Score: 0.8165333333333333\n",
      "F1 Score: 0.8826739427012278\n",
      "-------------------\n",
      "True Positives: 1294\n",
      "True Negatives: 237\n",
      "False Positives: 149\n",
      "False Negatives: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1260 out of 1260 | elapsed:   56.9s finished\n"
     ]
    }
   ],
   "source": [
    "#Decision Trees\n",
    "grid_params_dt = [{'criterion': ['gini','entropy'], \n",
    "                    'min_samples_leaf' : range(5,100,15),\n",
    "                    'max_depth': range(2,20,1)}] \n",
    "\n",
    "gs_dt = GridSearchCV(estimator=DecisionTreeClassifier(),\n",
    "                    param_grid=grid_params_dt,\n",
    "                    scoring='f1',\n",
    "                    cv=5,\n",
    "                    verbose=1)\n",
    "gs_dt.fit(X_train_scaled, y_train)\n",
    "# examine the best model\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(gs_dt.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(gs_dt.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(gs_dt.best_estimator_)\n",
    "\n",
    "#print results\n",
    "print('Decision Trees')\n",
    "print('-------------------')\n",
    "\n",
    "print('train')\n",
    "train_preds = gs_dt.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = gs_dt.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8960676390299402\n",
      "{'criterion': 'gini', 'max_depth': 19, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 20}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=19, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\n",
      "\n",
      "Random Forest\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 0.962298927613941\n",
      "Recall Score: 0.9709213863060017\n",
      "Accuracy Score: 0.9664412510566357\n",
      "F1 Score: 0.9665909282167803\n",
      "\n",
      "test\n",
      "Precision Score: 0.91283459162663\n",
      "Recall Score: 0.9035326086956522\n",
      "Accuracy Score: 0.8565333333333334\n",
      "F1 Score: 0.9081597814953909\n",
      "-------------------\n",
      "True Positives: 1330\n",
      "True Negatives: 276\n",
      "False Positives: 127\n",
      "False Negatives: 142\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "grid_params_rf = [{'criterion': ['gini','entropy'], \n",
    "                    'min_samples_leaf' : range(1,6,1),\n",
    "                    'max_depth': range(2,20,1),\n",
    "                    'n_estimators': range(10,21,10),\n",
    "                    'min_samples_split' : range(2,10,2)}] \n",
    "\n",
    "gs_rf = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                    param_grid=grid_params_rf,\n",
    "                    scoring='f1',\n",
    "                    cv=5,\n",
    "                    verbose=5)\n",
    "gs_rf.fit(X_train_scaled, y_train)\n",
    "# examine the best model\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(gs_rf.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(gs_rf.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(gs_rf.best_estimator_)\n",
    "print('\\n')\n",
    "#print results\n",
    "print('Random Forest')\n",
    "print('-------------------')\n",
    "\n",
    "print('train')\n",
    "train_preds = gs_rf.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = gs_rf.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9029214725119428\n",
      "{'alpha': 0, 'colsample_bytree': 1, 'eta': 0.1, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "XGBClassifier(alpha=0, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, eta=0.1, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=9, min_child_weight=1, missing=None,\n",
      "       n_estimators=100, n_jobs=1, nthread=None,\n",
      "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1)\n",
      "\n",
      "\n",
      "XGBoost\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 0.9499253855082076\n",
      "Recall Score: 0.9685545224006763\n",
      "Accuracy Score: 0.958748943364328\n",
      "F1 Score: 0.9591495061108322\n",
      "\n",
      "test\n",
      "Precision Score: 0.9103260869565217\n",
      "Recall Score: 0.9103260869565217\n",
      "Accuracy Score: 0.8592\n",
      "F1 Score: 0.9103260869565217\n",
      "-------------------\n",
      "True Positives: 1340\n",
      "True Negatives: 271\n",
      "False Positives: 132\n",
      "False Negatives: 132\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "grid_params_xgb = [{'max_depth': range(2,10,1),\n",
    "                    'learning_rate': [0.01, 0.1, 1],\n",
    "                    'colsample_bytree': [0.01, 0.1, 1],\n",
    "                    'alpha': [0, 0.1, 1],\n",
    "                    'eta': [0.1, 0.3, 0.5]}] \n",
    "\n",
    "gs_xgb = GridSearchCV(estimator=XGBClassifier(),\n",
    "                    param_grid=grid_params_xgb,\n",
    "                    scoring='f1',\n",
    "                    cv=5,\n",
    "                    verbose=5)\n",
    "gs_xgb.fit(X_train_scaled, y_train)\n",
    "# examine the best model\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(gs_xgb.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(gs_xgb.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(gs_xgb.best_estimator_)\n",
    "print('\\n')\n",
    "#print results\n",
    "print('XGBoost')\n",
    "print('-------------------')\n",
    "\n",
    "print('train')\n",
    "train_preds = gs_xgb.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = gs_xgb.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#prints out a confusion matrix\n",
    "def show_cf(y_true, y_pred, class_names=None, model_name=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    cf = confusion_matrix(y_true, y_pred)\n",
    "    plt.imshow(cf, cmap=plt.cm.Blues)\n",
    "    \n",
    "    if model_name:\n",
    "        plt.title(\"Confusion Matrix: {}\".format(model_name), fontsize=15)\n",
    "    else:\n",
    "        plt.title(\"Confusion Matrix\", fontsize=15)\n",
    "    plt.ylabel('True Label', fontsize=15)\n",
    "    plt.xlabel('Predicted Label', fontsize=15)\n",
    "    \n",
    "    class_names = set(y_true)\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    if class_names:\n",
    "        plt.xticks(tick_marks, class_names)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    thresh = cf.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cf.shape[0]), range(cf.shape[1])):\n",
    "        plt.text(j, i, cf[i, j], horizontalalignment='center', color='white' if cf[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "-------------------\n",
      "train\n",
      "Precision Score: 0.9499253855082076\n",
      "Recall Score: 0.9685545224006763\n",
      "Accuracy Score: 0.958748943364328\n",
      "F1 Score: 0.9591495061108322\n",
      "\n",
      "test\n",
      "Precision Score: 0.9103260869565217\n",
      "Recall Score: 0.9103260869565217\n",
      "Accuracy Score: 0.8592\n",
      "F1 Score: 0.9103260869565217\n",
      "-------------------\n",
      "True Positives: 1340\n",
      "True Negatives: 271\n",
      "False Positives: 132\n",
      "False Negatives: 132\n"
     ]
    }
   ],
   "source": [
    "#print best model\n",
    "print('XGBoost')\n",
    "print('-------------------')\n",
    "\n",
    "print('train')\n",
    "train_preds = gs_xgb.predict(X_train_scaled)\n",
    "print_metrics(y_train, train_preds)\n",
    "print('\\ntest')\n",
    "test_preds = gs_xgb.predict(X_test_scaled)\n",
    "print_metrics(y_test, test_preds)\n",
    "\n",
    "print('-------------------')\n",
    "confusion = metrics.confusion_matrix(y_test, test_preds)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print ('True Positives:', TP)\n",
    "print ('True Negatives:', TN)\n",
    "print ('False Positives:', FP)\n",
    "print ('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAI1CAYAAAA3nuU+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcHFW5//HPk0TZl5AQDIRNCQhykSUEBEFkkUTZRIEgKiiICih6uQrKD0JYBEXFC6KIsiqyuhAEApgQVC4gYd8h7CFsIex75Pn9UTWhM8xMeiYz3Z3U582rXzNddbrqdGfCPPmeU6ciM5EkSaqyfs3ugCRJUrNZEEmSpMqzIJIkSZVnQSRJkirPgkiSJFWeBZEkSao8CyJJklR5FkSSJKnyLIgkSVLlWRBJkqTKG9DsDkiSpObpv+TKmbNeb8i58vVnr8jMUQ05WTdZEEmSVGE563UWWmPXhpzrjVtPHtyQE/WABZEkSZUWEM6g8ROQJEmVZ0IkSVKVBRDR7F40nQmRJEmqPAsiSZJUeQ6ZSZJUdU6qNiGSJEkyIZIkqeqcVG1CJEmSZEIkSVKluTAjmBBJkiSZEEmSVHnOITIhkiRJMiGSJKnKAucQYUIkSZJkQiRJUrWFc4gwIZIkSTIhkiSp8pxDZEIkSZJkQiRJUtU5h8iESJIkyYJIkiRVnkNmkiRVmjd3BRMiSZIkEyJJkiotcFI1JkSSJEkmRJIkVZ5ziEyIJEmSLIjUciJi54iYFBEvRMSbEXF/RBwdEYP76HybRsTNEfFGRGQvHveIiJjRW8er83wZEQ90sn9quf+Ibh53ZHdeExFblOdZuzvnqfPYYyPi1YhYpd32lSLilYg4pt325SLi5+XP0Btlm5si4qCIWKqm3V5ln9seb0bEfRHxw4jo39vvox4RsW9E7NSMc6tqyqvMGvFoYa3dO1VORPwMuBB4CPgS8CngBGB74Ld9dNrfAC8A2wIf68Xj/q48ZiO9AawaESNqN0bEhsDK5f7uGgmM7Ub7myk+xwd7cK65OQ6YDpzYbvuJwLPA0W0bIuLDwC3ADsAvgdHA54C/AQeX29rbkqLv2wJ/AI4q2zbDvoAFkdQgziFSy4iI7YH/BvbOzNNrdl0TEadSFEd94cPAqZl5TW8eNDOnAdN685h1eJWiIBkDTKnZPgaYBGzQVyeOiAAWysyXgOv74hyZ+WZEHABMiIgdMnN8+XOzI7BDZr5e0/yPwAzg42Wf2lxRFt6f6eAUN2bmK+X3kyPivyiKkh/1/ruRWkg/rzIzIVIr+S5wc7tiCIDM/E9mXt72PCIGR8RZEfFcRLwWEZM7SEUeiYifRsR3I2JaRDwfEedFxNLl/i3KIbL+wP+WQyVnlvuy/MVbe7w5hsAiYumI+F1ETC+HYx6LiN921r7ctmpE/DUiXoqIlyPikohYrV2bjIgDI+JHEfFsRDwTESdHxEJ1fo7nAbuWBUpbobJruX0OEfGxiBhfvodXI+LWiNijZv9ewEk1/cqImFz7/iLi4xFxI0X6tEv7IbOI2CUi3omIrWqOu0r5GRxNN2XmFcBFwIlRDKOeCIzPzEtqjv8JYD3gkHbFUNsxXsrMc+s43cvA+2o31Pmz17/8fB4rh9/uiogvtGvzkYiYEBEzy8/+nojYv9w3maJ43bPmc9+rjv5K6iELIrWEiHgfsAkwoc6X/JViWON/gN0ofpavbl9cUBQCW1EMPxwMbMe7/9pvG9oB+Fn5/VHd6PbPgY9TFHLbAj8EOp2DVBY0E4E1ga8BewGrUiRgy7RrfhCwPPBF4Hjg68CBdfbrz8ByZd8ANgOWBf7SQduVgWuBfSiGJf8EnBERu5f7L6X4bKD4fD4G7Ffz+kWBsyiGB0cB/25/gsy8EDgfOD0iliwLtNOBh4Ej29qVhcXkOt/jd4BBwI3AEODb7fZvDsyiSMW6o39EDIiIxSJiNMXPT/vPrZ6fvSOBQ4FTKYbsrgXOqflcAcYD/6H4M96BovBcoty3H3AvcBnvfu6XdvO9SPUJnEOEQ2ZqHYOAhYDH5tYwIkYBmwJbtA1zRcQk4BHgexTFQ5u3gZ0yc1bZbi2K4aP92oZ2yiDlkczs7jDPSODkzDy/Ztsfumj/FWAlYPXMfKjszw0U86W+Dhxb0/aRzNyr/P6KiNgU2Bn4ydw6lZkvRMQEivf5z/LrhHJ7+7azU6OyUPkHMIyiYDs3M5+NiEfKth19PosA/52ZF9ccZ2gH7fYH7qSYD3YbRbG2YWa+VdPmP3N7bzX9fiIifkNROB6ZmY+2a7I8MCMz55gzFcUE6Xj3MNn+nC+0e/5naobL6vnZK4vb7wBHZ2ZbAnZFRAwDjgDOLZOtD1L8bN5RtplY8/7ujohXgWd78HMpqQdau1xTFdVzlddIil8Us+f8ZOarFJNlP96u7dVtxVDpbmBIRLx/nnsKtwLfi4j9ImL1OtqPpBgSfKhtQznP6Fre2+8r2z2/m6JQqdd5wOfLVOrzdDBcBhARAyPixIh4lKJ4fJsiTavn/UDx53X5XBtlzqQosr5KkXiNy8zb2rXZKjO36uj1HfR7CYpCL4FPdNSEjn+WXuTd9/l0B/s3BzakSGT2BjZmzsn89fzsrU2RnF3Y7tjnA6tHxBBgJvA4cEpE7FZuk5onojGPFmZBpFbxHPAmRYIyN0Pp+JfZ00D7oaf2/+J/i+KXZW8URAdQDJ8cDtwXEQ9ExJgu2s9rvxfuRt/GA4sDxwCLAZd00u5MimGf4ykmrW9IMZxV77meb5fydGUSxXvtx7xfMTiO4n3tBnyidt5T6Qlg2Q7mXW1G8R47O/8tmTklM68v57J9G9gr3l1CoJ4/w6E129q3ARiYme9QfN5PUXzeT0XEPyNivU76JamPWRCpJWTm2xRJST2XqT9JMW+kveUo/uXdG97kvUXTHEVLZr6Qmd/OzA8AHwVuoJgnslYnx2xEv9v61pZafBe4pHw+h4hYmOJKq7GZ+cvMnJSZU+je/xe6s27TcRQT2J8CftGN180hiiu/vgUcWs5POgc4PiKWrGn2D4opAZ+co7OZt5TvcXqdp7u7/Lpm+bWeP8Mny6/t2y1Xfp1Z9uXezPwcsDSwNUURemlEi0+00ALIdYjAgkit5RfAiIjYs/2OiOhXzt+AovAYEhGb1+xflOKX+796qS/TePeXIOUvqS07a5yZt1PMIelHcRl/R24ANoiIVWuOuwLFZPLe6netX1MkQ6d0sn8higLlzZr+LEExwbfWW+W+7iRUcyiv+voW8E2KoajdI+JzPThOULyv23j3ff0PRVo0rq1dOaR1C3Bs+Z56qi0Zerz8Ws/P3p3Aa8Au7Y61K3B/Zj5buzEz387MSRST9IdSFEjQ/VRQ0jxwUrVaRmZeEhE/B04rJxFfDLxCUWB8g2Li6oTMvCIirgXOj4hDKIbb/odigu/xvdSdvwD7R8QtFJOe9wFqEwgi4l9luzspkpKvUawD9J4rrUpnUlzpdnlEHE4xifgIirVyftNL/Z4tMycDk7vY/2J5ufzhEfES8A5wCMU8m9r3em/59cByAvFLmXlfvf2IiMWBM4DzM/OicttvgF9HxD/aCoSImFj2q6t5RF+hvOqqHHYiM5+KiLEUKdHpNZOUv0AxTHdzRJxI8efUHxhOMdT2ynuODhtGxOsU/29ck6LImlI+qOdnLzNnRsQvgP8XEbPK1+4MfBrYvXyv6wA/pZhX9BAwkOJn47ZyvhUUn/u2EbFteZ6HM/O5Lj4bSfPAgkgtJTMPioj/o5if80eKXzSPUMyJ+WlN089SXA7+C4p/Rf8b2DIzp/ZSV8ZRDHkcTfEv9V9S/EKtXZvoOopL51ehKG5uAUaXE6Xfo1xUcGuKJOA0irlMk4Gda34JNtoXKC4NP5vil+4vKSYE177Pf1L8sj+Q4kq4fwBbdOMcP6P4c6w95v9QzKE5hWL1aCiKlU6VV2/9GPhdZrYvOk+iKJZOppgYTWbeGxHrA9+nmAu0IsWl+PcDF5Svaa/tMv3/UKSElwCHt5uYX8/P3uHlub5JMVQ2FfhizVV9T1HMKTqU4oq4F4CrmXNV7KMp5tRdQFGgfoWiqJZ6X4tPeG6EyOy1WzdJkqT5TL8lh+VCG32rIed64++H3JSZI+besvFMiCRJqroWn/DcCH4CkiSp8kyIJEmqsvlg0cRGMCGSJEmVZ0IkSVLVOYeo9QuiZQYNzmErrtzsbkiV877+RuhSMzz66CPMmDHDv4AN1vIF0bAVV+aSidc2uxtS5Sy3lIskS82w6UZNuCrdOUTOIZIkSWr5hEiSJPWlcA4RJkSSJEkmRJIkVZ5ziEyIJEmSTIgkSaqywDlEmBBJkiRZEEmSJDlkJklSpXnZPZgQSZKkFhERp0fEMxFxZ8224yPi3oi4PSL+EhFL1+z7QURMjYj7ImLbmu2jym1TI+KQes5tQSRJUtVFNOYxd2cCo9ptuwpYOzPXAe4HflB0OdYCxgAfKV/zq4joHxH9gZOB0cBawO5l2y5ZEEmSpJaQmf8AZrbbdmVmziqfXg8MK7/fETgvM9/MzIeBqcDI8jE1Mx/KzLeA88q2XXIOkSRJVTf/zCH6KnB++f0KFAVSm2nlNoDH223faG4HtiCSJEmNMjgiptQ8PzUzT63nhRFxKDALOKdtUwfNko5Hv3Jux7cgkiSp6hp3644ZmTmiuy+KiD2B7YCtMrOtuJkGrFjTbBgwvfy+s+2dmm8yMkmSVD0RMQo4GNghM1+r2TUeGBMRC0XEqsBw4N/AjcDwiFg1It5PMfF6/NzOY0IkSVKVReusQxQR5wJbUAytTQPGUlxVthBwVRRJ1vWZ+Y3MvCsiLgDuphhK2z8z/1Me5wDgCqA/cHpm3jW3c1sQSZKklpCZu3ew+bQu2h8DHNPB9suAy7pzbgsiSZKqrnFziFpWa2RkkiRJTWRCJElSxYUJkQmRJEmSCZEkSRUWmBCBCZEkSZIFkSRJkkNmkiRVWdDxXcEqxoRIkiRVngmRJEmVFk6qxoRIkiTJhEiSpKozITIhkiRJMiGSJKnqTIhMiCRJkkyIJEmqOhMiEyJJkiQTIkmSKs2VqgETIkmSJBMiSZKqLFypGjAhkiRJMiGSJKnqTIhMiCRJkiyIJEmSHDKTJKniHDIzIZIkSTIhkiSp6kyITIgkSZJMiCRJqjRv3QGYEEmSJJkQSZJUdc4hMiGSJEkyIZIkqcq8uWvBhEiSJFWeCZEkSRVnQmRCJEmSZEIkSVLlGRCZEEmSJJkQSZJUZeEcIjAhkiRJMiGSJKnqTIhMiCRJkiyIJEmSHDKTJKniHDIzIZIkSTIhkiSpyry5a8GESJIkVZ4JkSRJVWdAZEIkSZJkQiRJUpV56w7AhEiSJMmESJKkqjMhMiGSJEkyIZIkqepMiEyIJEmSTIgkSao8AyITIkmSJBMiSZIqzjlEJkSSJEkWRJIkSQ6ZSZJUYRHhkBkmRJIkSSZEkiRVnQmRCZEkSZIJkSRJVWdCZEIkSZJkQiRJUuUZEJkQSZIkmRBJklRxziEyIZIkSTIhkiSp0sKECEyIJEmSTIgkSaqyAAyITIgkSZJMiCRJqjbvdg8mRJIkSRZEkiRJDplJklRxjpiZEEmSJJkQSZJUdU6qNiGSJEmyIJIkqdKimEPUiMdcuxJxekQ8ExF31mxbJiKuiogHyq8Dy+0RESdGxNSIuD0i1q95zZ5l+wciYs96PgYLIkmS1CrOBEa123YIMDEzhwMTy+cAo4Hh5WNf4NdQFFDAWGAjYCQwtq2I6ooFkSRJFRZAv37RkMfcZOY/gJntNu8InFV+fxawU832s7NwPbB0RAwFtgWuysyZmfk8cBXvLbLew4JIPTL9iccZs+O2bPWxddlm0/U5/Te/BGD/vb/I6C02YvQWG7HpemsweouNAHh+5nOM2XFb1lp5MIcf/J1mdl2a7319n6+y0vJD2GDdtWdvGzf2MDZcbx022mBdthv9KaZPnw7AuX88hw3XW4cN11uHLTbbhNtvu61Z3ZZ6arnMfBKg/Dqk3L4C8HhNu2nlts62d8mrzNQjA/oP4P8deRxrf3Q9Xnn5ZbbfahM222IrTj7tD7PbHH3YwSyx5FIALLTQwhz0g8O57567uf/eu5rVbWmB8KU99+Ib+x3APl/98uxt3z3oe4wddxQAJ590IscefSQn/eoUVlllVa6cdA0DBw7kigmXs/839+Wf/3dDs7quFtXAi8wGR8SUmuenZuapPTxWR73OLrZ3yYJIPTLkA0MZ8oGhACy+xBJ8aPUP89ST0xm+xpoAZCaXXvwn/viXCQAsuthibLjxpjzy8ENN67O0oPj4Zpvz6COPzLFtySWXnP39a6+9Ovsy6o9tssns7SM32pgnnpjWkD5KnZiRmSO6+ZqnI2JoZj5ZDok9U26fBqxY024YML3cvkW77ZPndhKHzDTPHn/sUe6+41bW3WDD2dv+fd21DF52OVb90GpN7JlULWMPO5TVVl2R8849h8OOOPI9+8884zS23XZ0E3qmVhcRDXn00Hig7UqxPYGLa7Z/ubzabGPgxXJI7QrgUxExsJxM/alyW5caXhBFxKiIuK+8TO6Qub9CrezVV17hm3vtzuHHHM8SS7z7L9Txf76AHXbepYk9k6pn3FHHMPXhxxmz+x6c8qtfzrHvmslXc9YZp3H0sT9uUu+kuYuIc4HrgDUiYlpE7A0cB2wTEQ8A25TPAS4DHgKmAr8F9gPIzJnAUcCN5ePIcluXGjpkFhH9gZMp3tA04MaIGJ+ZdzeyH+odb7/9Nt/4yu7s9PndGLXdTrO3z5o1iysuvZhLJl7bxN5J1bXrmC+w846f4bCx4wC44/bb+ebX9+HiSy5n0KBBTe6dWk6dawQ1Qmbu3smurTpom8D+nRzndOD07py70QnRSGBqZj6UmW8B51FcNqf5TGZy8IHfYLXV12Cf/Q6cY9+/rpnEB1dbnaHLD2tS76TqmfrAA7O/v/SS8ay+xocBeOyxxxiz686cdsbvGb766s3qntTyGj2puqNL4TZqcB/UC6bc8H/8+YI/8uG11p59af33Dx3HJ7cZxSV/uZAddt71Pa/ZdL01eOXll3n77be48rJL+P1Ff5s9CVtS/b78xd355zWTmTFjBh9aZRiHHT6OCRMu44H776Nf9GOllVfmxJNPAeDYo49k5nPP8Z1v7QfAgAEDuPaGKV0dXhUTeC8zgCgSpwadLGIXYNvM3Kd8/iVgZGZ+q127fSlWnWSFYStucO2t9zesj5IKyy21cLO7IFXSphuN4KabpjSsQll0+dVztX1+1ZBz3XHUNjf14Cqzhmj0kFlnl8jNITNPzcwRmTlimUHLNqxzkiSpmho9ZHYjMDwiVgWeAMYAX2hwHyRJ0mzzdEn8AqOhBVFmzoqIAyjWA+gPnJ6ZLlssSZKaquErVWfmZRRrB0iSpBZgQORK1ZIkSd7LTJKkqnMOkQmRJEmSCZEkSZXWQrfuaCYTIkmSVHkmRJIkVZi37iiYEEmSpMozIZIkqeIMiEyIJEmSTIgkSao65xCZEEmSJJkQSZJUdQZEJkSSJEkWRJIkSQ6ZSZJUZeGkajAhkiRJMiGSJKnKilt3NLsXzWdCJEmSKs+ESJKkSgvnEGFCJEmSZEIkSVLVGRCZEEmSJJkQSZJUdc4hMiGSJEkyIZIkqdLCOURgQiRJkmRCJElSlRUrVRsRmRBJkqTKMyGSJKniTIhMiCRJkiyIJEmSHDKTJKniHDEzIZIkSTIhkiSp6pxUbUIkSZJkQiRJUqV56w7AhEiSJMmESJKkKgvCOUSYEEmSJJkQSZJUdQZEJkSSJEkmRJIkVV0/IyITIkmSJBMiSZIqzoDIhEiSJMmESJKkKovwXmZgQiRJkmRBJEmS5JCZJEkV188RMxMiSZIkEyJJkirOSdUmRJIkSSZEkiRVnQGRCZEkSZIJkSRJVRZAYERkQiRJkirPhEiSpIpzHSITIkmSJBMiSZIqLcJ1iDAhkiRJMiGSJKnqDIhMiCRJkkyIJEmqsgD6GRGZEEmSJFkQSZKkynPITJKkinPEzIRIkiTJhEiSpKpzYcYuCqKI2LI7B8rMSfPeHUmSpMbrKiH6O5AUV+TNTQL9e6VHkiSpYSKcQwRdF0RrNqwXkiRJTdRpQZSZ9zWyI5IkqTlcmLEbV5lFxICI+EpEnBwR4yPiQ+X2z0bE8L7roiRJUt+qqyCKiA8C9wAnAh8FPgMsVe7eBvhhn/ROkiT1uWjQo5XVmxCdCDwHrApswZzvazKwea/2SpIkVVJEfDci7oqIOyPi3IhYOCJWjYgbIuKBiDg/It5ftl2ofD613L9KT89bb0G0BXB0Zs6guKKs1lPA0J52QJIkNVdENORRRz9WAL4NjMjMtSmuYB8D/Bg4ITOHA88De5cv2Rt4PjNXA04o2/VIvQXR28D7Otk3FHippx2QJEmqMQBYJCIGAIsCTwJbAheV+88Cdiq/37F8Trl/q+jhKpP1FkR/Bw6JiMVrtmXZ2f2BCT05uSRJaq4A+kVjHnOTmU8APwUeoyiEXgRuAl7IzFlls2nACuX3KwCPl6+dVbYf1JPPod6C6HvAisD9wG8phs0OAW4DPggc2pOTS5KkShkcEVNqHvvW7oyIgRSpz6rA8sBiwOgOjtM2faejMqv91J661HUvs8x8JCI+Cnwf2Ap4AliDIhn6SWY+3ZOTS5KkJqtzfk8vmZGZI7rYvzXwcGY+CxARfwY2AZaOiAFlCjQMmF62n0YR2EwrR62WAmb2pGN139y17Nz3enISSZKkOjwGbBwRiwKvU4QwU4Crgc8D5wF7AheX7ceXz68r90/KzL5LiNpExGIUt/QYSlGd3ZuZr/bkxJIkSbUy84aIuAi4GZgF3AKcClwKnBcRR5fbTitfchrw+4iYSpEMjenpuesqiCKiHzAWOBBYsmbXyxHxv8C4zPxPTzshSZKap5Xu3JGZYylqjloPASM7aPsGsEtvnLfehOinFFeT/Rj4M/AMMAT4HHAwxaSng3qjQ5IkSY1Wb0G0J3BYZv6kZtt04NaIeIVisrUFkSRJ86EGTqpuWfVedh/ArZ3su5XWv0WJJElSp+pNiM4F9gKu7GDfXsD5vdQfSZLUQG0LM1ZdpwVRRHy15umdwKERcTPFpW5tc4h2AgYDx/ZlJyVJkvpSVwnR7zrYtjywbgfbTwJ+1Ss9kiRJDeUcoq4LokUa1gtJkqQm6rQgysw3G9kRSZLUHOZD3V+pellgOLBw+32ZOam3OiVJktRI9a5UvRjwB2B7Oi8k+/dWpyRJUmNEQD/nENW9DtExwFrApygKot2B0cA5wCPAZn3ROUmSpEaotyDaHjgauKZ8/lBmXpmZX6a44doBfdE5SZLU9yIa82hl9RZEHwAeKW/g+howqGbfeODTvd0xSZKkRql3UvU03i2CpgKjgCvK5+sBb/RyvyRJUoO4DlH9BdFEYEvgr8CJwO8i4qPAm8DWwC/7pnuSJEl9r96C6GBgCYDMPD0iXgc+T7F44/cpVqqWJEmaL9VVEGXmy8DLNc/PpbjhKxExEFgf+HdfdFCSJPUtR8zqn1TdlS2B63rhOJIkSU3RrZWqJUnSgiUIF2akdxIiSZKk+ZoJkSRJVTYfLJrYCCZEkiSp8jpNiCLicSDrOMaivdcdSZLUaC7M2PWQ2TnUVxD1qff1D5ZbauFmd0OqnIEbeotCqRnevO+xZnehkjotiDLzkEZ2RJIkNYfzZ/wMJEmSvMpMkqQqC5xDBCZEkiRJJkSSJFVdPwMiEyJJkqRuJUQR8SGKO9uvCPwhM5+JiBWB5zLztb7ooCRJ6lsmRHUWRBGxCPAbYHfK+VfAZOAZ4BfAg8D3+6aLkiRJfaveIbOfAdsAOwBLURREbS4FRvdyvyRJUgNEFFeZNeLRyuodMtsFOCgzL4+I/u32PQys3LvdkiRJapx6E6LFgKe72PdO73RHkiSp8epNiG4CvgBc0cG+nYEbeq1HkiSpoZxUXX9BdDhwRUQMAi6kuOnr1hHxTYpC6ZN91D9JkqQ+V9eQWWZeDYwChgCnU0yqPo7iEvxPZ+Z1fdZDSZLUp4qJ1X3/aGV1r0OUmZOAkRGxFDAIeD4zn++znkmSJDVIt2/dkZkvAi/2QV8kSVKDBdCv1eObBqh3Ycaz59YmM788792RJElqvHoTouEdbFsG+CAwg2ItIkmSNB/yxqZ1FkSZ+bGOtpf3NrsQOLI3OyVJktRI81QUZuaDwLHAT3unO5IkqdG8yqx3UrI38dYdkiRpPlbvpOoPdrD5/cCaFAnRzb3ZKUmS1BgR4VVm1D+peirF6tTtBXAHsG+v9UiSJKnB6i2IRnew7Q1gWjmPSJIkzacMiOooiCJiIWBt4MrMvKPvuyRJktRYcy2IMvPNiDgSmNKA/kiSpAbzbvf1X2V2E/DRvuyIJElSs9Q7h+hA4LyIeA24DHiadpOsM/OdXu6bJElSQ9RbEN1Ufv1NF236z2NfJElSg3lz10K9BdF+dHzZvSRJ0nyv04IoIjYHbs7MVzLzlAb2SZIkNZABUdeTqq8G1mpURyRJkpqlqyEz60VJkhZ04WX30Ds3d5UkSZqvzW1S9acj4sP1HCgzz+6F/kiSpAYLB4XmWhAdXudxErAgkiRJ86W5FUSfxFt2SJK0wCrWIWp2L5pvbgXR65n5akN6IkmS1CT1LswoSZIWUCZEXmUmSZLUeUKUmRZLkiRVQLhUtQmRJEmSc4gkSaowrzIrmBBJkqTKsyCSJEmV55CZJElVFuCcahMiSZIkEyJJkqqunxGRCZEkSZIJkSRJFeZl9wUTIkmSVHkmRJIkVZxTiEyIJEmSTIgkSaq2oB9GRCZEkiSp8kyIJEmqsMA5RGBCJEmSZEEkSVKlRbEOUSMedXUnYumIuCgi7o2IeyLiYxGxTERcFREPlF8Hlm0jIk6MiKkRcXtErN/Tj8GCSJIktZL/BSZk5oeBjwL3AIcAEzNzODCxfA4wGhhePvYFft3TkzqHSJKkimuVe5lFxJLA5sBeAJn5FvBWROwIbFE2OwuYDBwM7AicnZkJXF+mS0Mz88nuntuESJIktYoPAs8CZ0TELRHxu4hYDFiurcgpvw4p268U8+5KAAATXUlEQVQAPF7z+mnltm6zIJIkSY0yOCKm1Dz2bbd/ALA+8OvMXA94lXeHxzrSUbSVPemYQ2aSJFVYgy+7n5GZI7rYPw2Ylpk3lM8voiiInm4bCouIocAzNe1XrHn9MGB6TzpmQiRJklpCZj4FPB4Ra5SbtgLuBsYDe5bb9gQuLr8fD3y5vNpsY+DFnswfAhMiSZIqr1UmVZe+BZwTEe8HHgK+QhHgXBARewOPAbuUbS8DPg1MBV4r2/aIBZEkSWoZmXkr0NGw2lYdtE1g/944rwWRJEkV11oBUXM4h0iSJFWeCZEkSRUWmI6An4EkSZIJkSRJlRYQTiIyIZIkSTIhkiSp4syHTIgkSZJMiCRJqrKg5VaqbgoTIkmSVHkmRJIkVZz5kAmRJEmSBZEkSZJDZpIkVZxzqk2IJEmSTIgkSaq28NYdmBBJkiSZEEmSVGWB6Qj4GUiSJJkQSZJUdc4hMiGSJEkyIZIkqerMh0yIJEmSTIgkSaq0cA4RmBBJkiSZEEmSVGWuQ1TwM5AkSZVnQiRJUsU5h8iESJIkyYJIkiTJITNJkirOATMTIkmSJBMiSZKqzjnVJkSSJEkmRJIkVVmxMKMRkQmRJEmqPBMiSZIqzjlEJkSaB1/f56ustPwQNlh37dnbxo09jA3XW4eNNliX7UZ/iunTpwNw7h/PYcP11mHD9dZhi8024fbbbmtWt6X50ilj9+DRiccy5cIfzt52+H6f4d/n/4DrzzuES361P0OXXWqO12yw1kq8MuVEPrv1urO37bH9Rtxx8eHccfHh7LH9Rg3rv9TqLIjUY1/acy8u/tuEObZ996DvceMtt3PDTbcy+tPbcezRRwKwyiqrcuWka7jxltv5waGHsf83921Gl6X51u8vuZ4d9z95jm0nnDWRkbsdy8ZjjuPyf97JD/YdPXtfv37B0QfuyFXX3TN728AlF+XQfUez+Zd+ymZfPJ5D9x3N0kss0rD3oFYVDfuvlVkQqcc+vtnmLLPMMnNsW3LJJWd//9prr86+P87HNtmEgQMHAjByo4154olpjeuotAC49uYHmfnia3Nse/nVN2Z/v+giC5GZs5/vN+YT/HXibTw78+XZ27bZZE0mXn8vz7/0Gi+8/DoTr7+XT226Vt93XpoPOIdIvW7sYYdyzh/OZqmllmLCVVe/Z/+ZZ5zGttuO7uCVkrrriP23Z4/tRvLiK68zat8TAVh+2aXYYcuPMmrfE9ngI3vMbrv8sksz7ennZz9/4pkXWH7ZpRveZ7Ue5xA1OCGKiNMj4pmIuLOR51VjjTvqGKY+/Dhjdt+DU371yzn2XTP5as464zSOPvbHTeqdtGA54uRLGD76MM67fArf2G1zAI7/3uf4f/97Me+8k3O07eiXXpLv3ShVUKOHzM4ERjX4nGqSXcd8gb/+5U+zn99x++188+v7cOGfLmbQoEFN7Jm04Lng8hvZaati8vT6a63E2cd9hXsvHcdnt16PX/xgN7bfYh2eeOYFhi03cPZrVhiyNE8++2KzuqwW0bYOUSMerayhQ2aZ+Y+IWKWR51RjTX3gAVYbPhyASy8Zz+prfBiAxx57jDG77sxpZ/ye4auv3swuSguMD620LA8+9iwAn/nEOtz/yNMArLndEbPbnDrui1z+zzu5ZPLtDFxyUcYdsP3sidRbf+zDHH7S+Ib3W2pFziFSj335i7vzz2smM2PGDD60yjAOO3wcEyZcxgP330e/6MdKK6/MiSefAsCxRx/JzOee4zvf2g+AAQMGcO0NU5rZfWm+ctaxe7HZBsMZvPTiTJ1wFEedchmjPv4Rhq88hHfeSR57cibfPua8Lo/x/EuvcexvJ/CvP3wfgB+dOoHnX3qty9eoAsI5RABRe1VCQ05YJER/y8y1u2izL7AvwIorrbTB/Q8+2pjOSZpt4IYHNLsLUiW9ed8FvPPaMw0rUVZfe9086YKrGnKuUR8ZclNmjmjIybqpJS+7z8xTM3NEZo5YdvCyze6OJElawDlkJklSxTlk1vjL7s8FrgPWiIhpEbF3I88vSZLUkUZfZbZ7I88nSZLmrtVvq9EILTmHSJIkqZGcQyRJUoUF0M+AyIRIkiTJhEiSpIpzDpEJkSRJkgmRJElV5zpEJkSSJEkmRJIkVZ1ziEyIJEmSTIgkSaoy1yEqmBBJkqTKMyGSJKnSwjlEmBBJkiRZEEmSJDlkJklSlYULM4IJkSRJkgmRJElVZ0BkQiRJkmRCJElSlRULM5oRmRBJkqTKMyGSJKnizIdMiCRJkkyIJEmqPCMiEyJJkiQTIkmSKs6bu5oQSZIkmRBJklR1LkNkQiRJkmRCJElS1RkQmRBJkiRZEEmSJFkQSZJUddGgRz1diegfEbdExN/K56tGxA0R8UBEnB8R7y+3L1Q+n1ruX2VePgILIkmS1EoOBO6pef5j4ITMHA48D+xdbt8beD4zVwNOKNv1mAWRJEkVVoQ3jflvrn2JGAZ8Bvhd+TyALYGLyiZnATuV3+9YPqfcv1XZvkcsiCRJUqv4BfB94J3y+SDghcycVT6fBqxQfr8C8DhAuf/Fsn2PWBBJklRlUSzM2IgHMDgiptQ89p3djYjtgGcy86Y5e/ceWce+bnMdIkmS1CgzMnNEJ/s2BXaIiE8DCwNLUiRGS0fEgDIFGgZML9tPA1YEpkXEAGApYGZPO2ZCJElSxbXCRWaZ+YPMHJaZqwBjgEmZuQdwNfD5stmewMXl9+PL55T7J2VmjxMiCyJJktTKDgb+OyKmUswROq3cfhowqNz+38Ah83ISh8wkSaq6Frt3R2ZOBiaX3z8EjOygzRvALr11ThMiSZJUeSZEkiRVWn1rBC3oTIgkSVLlmRBJklRxPV/fecFhQiRJkirPhEiSpArrxo3oF2gmRJIkqfIsiCRJUuU5ZCZJUtU5ZmZCJEmSZEIkSVLFuTCjCZEkSZIJkSRJVefCjCZEkiRJJkSSJFWdAZEJkSRJkgmRJEmV5r07ABMiSZIkEyJJkqrOdYhMiCRJkkyIJEmqssB1iMCESJIkyYRIkqSqMyAyIZIkSTIhkiSp8oyITIgkSZIsiCRJUuU5ZCZJUsW5MKMJkSRJkgmRJElV58KMJkSSJEkmRJIkVZ0BkQmRJEmSCZEkSZVnRGRCJEmSZEIkSVKFBa5DBCZEkiRJJkSSJFVauA4RmBBJkiSZEEmSVHUGRCZEkiRJJkSSJFWeEZEJkSRJkgWRJEmqPIfMJEmqtHBhRkyIJEmSTIgkSao6F2Y0IZIkSTIhkiSpygKvugcTIkmSJBMiSZIqz4jIhEiSJMmESJKkinMdIhMiSZIkEyJJkqrOdYhMiCRJkkyIJEmqOgMiEyJJkiQTIkmSKi2cQwQmRJIkSRZEkiRJDplJklR5jpmZEEmSpMozIZIkqcICJ1WDCZEkSZIJkSRJVWdAZEIkSZLU+gnRzTffNGOR98Wjze6HemQwMKPZnZAqyL9787eVG31C5xDNBwVRZi7b7D6oZyJiSmaOaHY/pKrx757UfS1fEEmSpL4VziJyDpEkSZIJkfrSqc3ugFRR/t1T9xgQmRCp72Sm/1OWmsC/e1L3mRBJklRxBkQmROojETEqIu6LiKkRcUiz+yNVQUScHhHPRMSdze6LNL+xIFKvi4j+wMnAaGAtYPeIWKu5vZIq4UxgVLM7oflLROMercyCSH1hJDA1Mx/KzLeA84Adm9wnaYGXmf8AZja7H9L8yIJIfWEF4PGa59PKbZIktSQnVasvdBSMZsN7IUmqiwszmhCpb0wDVqx5PgyY3qS+SJI0VxZE6gs3AsMjYtWIeD8wBhjf5D5JkjoTDXq0MAsi9brMnAUcAFwB3ANckJl3NbdX0oIvIs4FrgPWiIhpEbF3s/skdUdErBgRV0fEPRFxV0QcWG5fJiKuiogHyq8Dy+0RESeWS7zcHhHr9/TcziFSn8jMy4DLmt0PqUoyc/dm90HzpxYKb2YBB2XmzRGxBHBTRFwF7AVMzMzjyrXtDgEOpljeZXj52Aj4dfm120yIJElSS8jMJzPz5vL7lylGGVagWLrlrLLZWcBO5fc7Amdn4Xpg6YgY2pNzmxBJklRxrbhoYkSsAqwH3AAsl5lPQlE0RcSQsllny7w82d3zWRBJkqRGGRwRU2qen9rRzYgjYnHgT8B3MvOl6Lxi67VlXiyIJEmqtGjkOkQzMnNEl72JeB9FMXROZv653Px0RAwt06GhwDPl9l5b5sU5RJIkqSVEEQWdBtyTmT+v2TUe2LP8fk/g4prtXy6vNtsYeLFtaK27LIikboqIIyIiax7TI+JPEfGhPj7vRRExuV0/ZnTj9e8vX7NuL/bpgIjoMp6OiL3Kz2nxeTzXIxHx03k5Rs2xMiIO6I1jSfO7oKVu7rop8CVgy4i4tXx8GjgO2CYiHgC2KZ9DcTXzQ8BU4LfAfj39HBwyk3rmRd69q/gHgaOAiRHxkcx8tUF9+B1wSTfavx8YCzwC3NoXHZKkeZGZ/6LzVQC26qB9Avv3xrktiKSemVVe4glwfUQ8BvwT+DRwYfvGEdEf6J+Zb/VWBzJzGsX4uSRpHjlkJvWOm8qvqwBExJkRMSUidoqIu4A3KBcLi4iVIuK8iJgZEa9FxBURsUbtwcrVWi+LiNfLoaJ92p+woyGziBgUEb+JiCcj4o2IuC8ivlPufrn8ekbNcF9bfxeOiJ9ExOMR8WZE3FbG1LXHXigifhkRL5R9PwF43zx8ZrXHPi4i7oiIV8oVls+JiA900vawiHiqbHtORCzVbv8y5WfwdPkZ/F9E9GihNknVYUIk9Y5Vyq9Ptdv2E+BI4Gng4YhYBvgX8BzwDeA1ihVX/x4Rq2fm6+WkwouBwcDeFMXUOGAZ4IHOOhARiwCTgSFl+3uB1coHwJbAJOBo4NJyW9vkw4uAkRRDag8CuwLjI2JEZrYNrx0H7AMcCtwNfA3YpY7Pph5DgB9RXB2yLHAQMCki/isz/1PTbneKuQJfA4ZSfL6/a+tHRCwE/B1YGvgexZUo36T4fIdnZu2fj6RSK65D1GgWRFIPRUTb358PAr+iSGD+XtNkELB1TUFBRBwFLAasm5kzy23XUszr+SpwMsVS9OsBG2fmDWWbmygKlU4LIuDLwEeA9WvOOalm/43l1wdrhvuIiK2AzwBbZOY15eYrI2J1iuJnl4gYRFHAjc3Mn5Wvu4KiMJpnmfnVmv70p7gf1zSKCZb/qGm6CPCZzHylbPsq8PuIWDMz7wG+CKwNfCQzHyjb/B24j6LI+l5v9FfSgschM6lnBgFvl4/7KIqi3dpd7vlEbTFU2hq4CngpIgaURdXLFENubWtzjASebiuGADLzUd4dluvMlsAtHZxzbramSLaubetT2a+JNX36L2Bh3r3Ulcx8p/b5vIiI0eXQ1osU9zJqmxu1erumV7UVQ6U/U0zA3LDmvdxEkcYNqClar6l5L5L0HiZEUs+8SPHLNymKienl1Q61nu7gdYOBjYHdOtg3sfz6Ad5ddKzWM8ASXfRpED1Yrr7s0wcoirv22oar2ubztO9XR/3slojYkGItkb9QDMs9Q/G5Xk9RhHV6vnKI8RWK4TN49/Pt6L08OK99lRZUDVyYsWVZEEk9Myszp8ylTUfr88yk+OV/VAf72iY9P0Uxp6a9IcDrXZzvOd6dL9QdM4EnePdmiR1pm3szpGxf26d59VngWYqELQEiYuVO2s5xvnLe1OK8WwjOBKZQzBtq781e6KukBZQFkdRYEykmLN+VmZ0VNzcCYyNio5o5RCsB6wPXzuXYu0TEOpl5ewf72y75b5+6TKSYX/NKZt7bybHvoJjcvSPFZG0iol/5fF4tArzdLmHbo5O220TE4jXDZjtTFJ5txelE4FPAY5k5z+mVVAn1L5q4QLMgkhrr5xQTfydFxEkUycxywCeAf2XmuRQrr94GXBgRB1MUIkcy9+GpsykWKLsyIo6gmNu0KrB6Zh6SmW9FxMPArhFxZ3nc2ynmNF0BXBURPwbuApYE1gUWzswfZOZzEXEqMC4iZpVtvkaRztRrp4h4o922G8vzfycifkGx0OQm5WfUkdeBSyPieIphsuOBv2Rm2+Tusykmf08uV7V+iGIocSTwVGae0I3+SqoQCyKpgTJzRhT32zkGOIHi8vAnKS7Fv71skxGxA3AqcDpFIfQjiuXqB3dx7DciYkuKeThHUhQ1j1BcAdfmG8BPKa6GWwhYNTMfiYidgR8C3wFWohh6uhU4qea136dYd+hw4B3gDxQF3s/qfPu/72DbVzLzzLLw+xZFkXUdsB1wfwftz6MYWjyNohgbT83wWPkZfLJ8/+Mois1ngH+XbSW1E3S+NHSVxHvngUqSpKpYf4MRec21/27IuZZcpP9Nc7vbfbOYEEmSVHVGRK5DJEmSZEIkSVLFuQ6RCZEkSZIJkSRJVec6RCZEkiRJJkSSJFWdAZEJkSRJkgmRJEmVZ0RkQiRJkmRBJEmSKs8hM0mSKs6FGU2IJEmSTIgkSaqywIUZASIzm90HSZLUJBExARjcoNPNyMxRDTpXt1gQSZKkynMOkSRJqjwLIkmSVHkWRJIkqfIsiCRJUuVZEEmSpMqzIJIkSZVnQSRJkirPgkiSJFWeBZEkSaq8/w9yxduA1L3pZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_cf(y_test, test_preds, model_name='XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
